{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('merged_dataset.csv')\n",
    "X = df.drop('label', axis=1).values  # Features\n",
    "y = df['label'].values  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# SVM Pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# RNN Model\n",
    "def create_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# CNN Model\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap Keras models for use in scikit-learn\n",
    "rnn_model = KerasClassifier(build_fn=create_rnn_model, epochs=10, batch_size=10, verbose=0)\n",
    "cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=10, verbose=0)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "svm_param_grid = {'svm__C': [1, 10], 'svm__gamma': [0.001, 0.01]}\n",
    "rf_param_grid = {'rf__n_estimators': [50, 100], 'rf__max_depth': [10, 20]}\n",
    "rnn_param_grid = {'batch_size': [10, 20], 'epochs': [10, 20]}\n",
    "cnn_param_grid = {'batch_size': [10, 20], 'epochs': [10, 20]}\n",
    "\n",
    "# Define cross-validation folds\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grids = {}\n",
    "for model_name, pipeline, param_grid in [('SVM', svm_pipeline, svm_param_grid),\n",
    "                                         ('RandomForest', rf_pipeline, rf_param_grid),\n",
    "                                         ('RNN', rnn_model, rnn_param_grid),\n",
    "                                         ('CNN', cnn_model, cnn_param_grid)]:\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1, cv=cv)\n",
    "    grid_search.fit(X_train, np_utils.to_categorical(y_train) if model_name in ['RNN', 'CNN'] else y_train)\n",
    "    grids[model_name] = grid_search\n",
    "\n",
    "# Evaluate models\n",
    "for model_name, grid in grids.items():\n",
    "    if model_name in ['RNN', 'CNN']:\n",
    "        y_pred = grid.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    else:\n",
    "        y_pred = grid.predict(X_test)\n",
    "    print(f\"{model_name} Best Params: {grid.best_params_}\")\n",
    "    print(f\"{model_name} Accuracy: {grid.best_score_}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Select the best model\n",
    "best_model_name = max(grids, key=lambda name: grids[name].best_score_)\n",
    "best_model = grids[best_model_name].best_estimator_\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# Save the model if needed\n",
    "# best_model.model.save('best_model.h5')  # Uncomment this line to save the Keras model\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
