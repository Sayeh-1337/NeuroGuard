{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('merged_dataset.csv')\n",
    "# Define the column names\n",
    "columns = ['mfcc_' + str(i) for i in range(1, 301)] + ['label']\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = columns\n",
    "\n",
    "# Print the DataFrame with headers\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure TensorFlow to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# Print GPU devices\n",
    "tf.test.gpu_device_name()\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "\n",
    "# Print session data\n",
    "print(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('label', axis=1).values.astype(np.float32)  # Features\n",
    "#y = df['label'].values  # Labels\n",
    "y = df['label'].values.astype(np.float32)  # Labels\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# SVM Model\n",
    "svm_model = SVC()\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', svm_model)\n",
    "])\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', rf_model)\n",
    "])\n",
    "\n",
    "# RNN Model\n",
    "def create_rnn_model():\n",
    "    strategy = tf.distribute.OneDeviceStrategy('GPU:0')  # Use the first GPU\n",
    "    with strategy.scope():\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "        model.add(LSTM(32, return_sequences=False))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# CNN Model\n",
    "def create_cnn_model():\n",
    "    strategy = tf.distribute.OneDeviceStrategy('GPU:0')  # Use the first GPU\n",
    "    with strategy.scope():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap Keras models for use in scikit-learn\n",
    "rnn_model = KerasClassifier(build_fn=create_rnn_model, epochs=10, batch_size=10, verbose=1)\n",
    "cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "# Fit and evaluate models\n",
    "models = {#'SVM': svm_pipeline,\n",
    "          #'Random Forest': rf_pipeline,\n",
    "          'RNN': rnn_model,\n",
    "          'CNN': cnn_model}\n",
    "\n",
    "accuracy_values = []\n",
    "reports = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name in ['RNN', 'CNN']:\n",
    "        \n",
    "        model.fit(X_train, to_categorical(y_train))\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    accuracy_values.append(accuracy)\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    reports.append(report)\n",
    "\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    print(report)\n",
    "    print()\n",
    "\n",
    "model_names = list(models.keys())\n",
    "plt.bar(model_names, accuracy_values)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.show()\n",
    "\n",
    "for model_name, report in zip(model_names, reports):\n",
    "    print(f\"Classification Report for {model_name}:\")\n",
    "    print(report)\n",
    "    print()\n",
    "\n",
    "best_model_name = max(models, key=lambda name: models[name].score(X_test, y_test))\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Configure TensorFlow to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/path/to/dataset.csv')\n",
    "\n",
    "# Define the column names\n",
    "columns = ['mfcc_' + str(i) for i in range(1, 301)] + ['label']\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = columns\n",
    "\n",
    "# Print the DataFrame with headers\n",
    "print(df.head())\n",
    "\n",
    "X = df.drop('label', axis=1).values  # Features\n",
    "y = df['label'].values  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# SVM Pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# RNN Model\n",
    "def create_rnn_model():\n",
    "    strategy = tf.distribute.OneDeviceStrategy('GPU:0')  # Use the first GPU\n",
    "    with strategy.scope():\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "        model.add(LSTM(32, return_sequences=False))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# CNN Model\n",
    "def create_cnn_model():\n",
    "    strategy = tf.distribute.OneDeviceStrategy('GPU:0')  # Use the first GPU\n",
    "    with strategy.scope():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap Keras models for use in scikit-learn\n",
    "rnn_model = KerasClassifier(build_fn=create_rnn_model, epochs=10, batch_size=10, verbose=1)\n",
    "cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "svm_param_grid = {'svm__C': [1, 10], 'svm__gamma': [0.001, 0.01]}\n",
    "rf_param_grid = {'rf__n_estimators': [50, 100], 'rf__max_depth': [10, 20]}\n",
    "rnn_param_grid = {'batch_size': [10, 20], 'epochs': [10, 20]}\n",
    "cnn_param_grid = {'batch_size': [10, 20], 'epochs': [10, 20]}\n",
    "\n",
    "# Define cross-validation folds\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grids = {}\n",
    "for model_name, pipeline, param_grid in [('SVM', svm_pipeline, svm_param_grid),\n",
    "                                         ('RandomForest', rf_pipeline, rf_param_grid),\n",
    "                                         ('RNN', rnn_model, rnn_param_grid),\n",
    "                                         ('CNN', cnn_model, cnn_param_grid)]:\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1, cv=cv, verbose=2)\n",
    "    grid_search.fit(X_train, to_categorical(y_train) if model_name in ['RNN', 'CNN'] else y_train)\n",
    "    grids[model_name] = grid_search\n",
    "\n",
    "# Evaluate models\n",
    "for model_name, grid in grids.items():\n",
    "    if model_name in ['RNN', 'CNN']:\n",
    "        y_pred = grid.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    else:\n",
    "        y_pred = grid.predict(X_test)\n",
    "    print(f\"{model_name} Best Params: {grid.best_params_}\")\n",
    "    print(f\"{model_name} Accuracy: {grid.best_score_}\")\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Select the best model\n",
    "best_model_name = max(grids, key=lambda name: grids[name].best_score_)\n",
    "best_model = grids[best_model_name].best_estimator_\n",
    "print(f\"Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop('label', axis=1).values  # Features\n",
    "# y = df['label'].values  # Labels\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define a standard scaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # SVM Pipeline\n",
    "# svm_pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('svm', SVC())\n",
    "# ])\n",
    "\n",
    "# # Random Forest Pipeline\n",
    "# rf_pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('rf', RandomForestClassifier())\n",
    "# ])\n",
    "\n",
    "# # RNN Model\n",
    "# def create_rnn_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "#     model.add(LSTM(32, return_sequences=False))\n",
    "#     model.add(Dense(4, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # CNN Model\n",
    "# def create_cnn_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(50, activation='relu'))\n",
    "#     model.add(Dense(4, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Wrap Keras models for use in scikit-learn\n",
    "# rnn_model = KerasClassifier(build_fn=create_rnn_model, epochs=10, batch_size=10, verbose=0)\n",
    "# cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=10, verbose=0)\n",
    "\n",
    "# # Define parameter grid for GridSearchCV\n",
    "# svm_param_grid = {'svm__C': [1, 10], 'svm__gamma': [0.001, 0.01]}\n",
    "# rf_param_grid = {'rf__n_estimators': [50, 100], 'rf__max_depth': [10, 20]}\n",
    "# rnn_param_grid = {'batch_size': [10, 20], 'epochs': [10, 20]}\n",
    "# cnn_param_grid = {'batch_size': [10, 20], 'epochs': [10, 20]}\n",
    "\n",
    "# # Define cross-validation folds\n",
    "# cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# # Perform GridSearchCV\n",
    "# grids = {}\n",
    "# for model_name, pipeline, param_grid in [('SVM', svm_pipeline, svm_param_grid),\n",
    "#                                          ('RandomForest', rf_pipeline, rf_param_grid),\n",
    "#                                          ('RNN', rnn_model, rnn_param_grid),\n",
    "#                                          ('CNN', cnn_model, cnn_param_grid)]:\n",
    "#     grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1, cv=cv)\n",
    "#     grid_search.fit(X_train, to_categorical(y_train) if model_name in ['RNN', 'CNN'] else y_train)\n",
    "#     grids[model_name] = grid_search\n",
    "\n",
    "# # Evaluate models\n",
    "# for model_name, grid in grids.items():\n",
    "#     if model_name in ['RNN', 'CNN']:\n",
    "#         y_pred = grid.predict(X_test)\n",
    "#         y_pred = np.argmax(y_pred, axis=1)\n",
    "#     else:\n",
    "#         y_pred = grid.predict(X_test)\n",
    "#     print(f\"{model_name} Best Params: {grid.best_params_}\")\n",
    "#     print(f\"{model_name} Accuracy: {grid.best_score_}\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Select the best model\n",
    "# best_model_name = max(grids, key=lambda name: grids[name].best_score_)\n",
    "# best_model = grids[best_model_name].best_estimator_\n",
    "# print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# # Save the model if needed\n",
    "# # best_model.model.save('best_model.h5')  # Uncomment this line to save the Keras model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuroGuard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
