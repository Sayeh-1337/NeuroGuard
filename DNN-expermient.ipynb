{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "<tensorflow.python.client.session.Session object at 0x00000197D9FE76D0>\n",
      "\u001b[33m###################\n",
      "# Loading Dataset #\n",
      "###################\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from colorama import Fore, Style\n",
    "# Set GPU device\n",
    "# Configure TensorFlow to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# Print GPU devices\n",
    "tf.test.gpu_device_name()\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "\n",
    "# Print session data\n",
    "print(sess)\n",
    "\n",
    "def print_decorative_log(message, color=Fore.BLUE, style=Style.RESET_ALL):\n",
    "    line_length = len(message) + 4  # Length of the message plus padding on both sides\n",
    "    decorative_line = \"#\" * line_length\n",
    "    print(color + decorative_line)\n",
    "    print(f\"# {message} #\")\n",
    "    print(decorative_line + style)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "print_decorative_log(\"Loading Dataset\", Fore.YELLOW)\n",
    "df = pd.read_csv('merged_dataset.csv')\n",
    "# Define the column names\n",
    "columns = ['mfcc_' + str(i) for i in range(1, 301)] + ['label']\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m##################\n",
      "# Dataset Loaded #\n",
      "##################\u001b[0m\n",
      "\u001b[33m#####################################\n",
      "# Dataset preparation and splitting #\n",
      "#####################################\u001b[0m\n",
      "\u001b[33m###################################\n",
      "# Normalization & Standardization #\n",
      "###################################\u001b[0m\n",
      "\u001b[33m#######################\n",
      "# ADASYN Oversampling #\n",
      "#######################\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_decorative_log(\"Dataset Loaded\", Fore.GREEN)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Configure TensorFlow to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# # Dropping rows with label equal to 3\n",
    "# df = df[df['label'] != 3]\n",
    "\n",
    "print_decorative_log(\"Dataset preparation and splitting\", Fore.YELLOW)\n",
    "X = df.drop('label', axis=1).values.astype(np.float32)  # Features\n",
    "#y = df['label'].values  # Labels\n",
    "y = df['label'].values.astype(np.float32)  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a standard scaler\n",
    "print_decorative_log(\"Normalization & Standardization\", Fore.YELLOW)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Apply SMOTE oversampling to address class imbalance\n",
    "# print_decorative_log(\"Applying SMOTE\", Fore.YELLOW)\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "#Define ADASYN oversampling\n",
    "print_decorative_log(\"ADASYN Oversampling\", Fore.YELLOW)\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Create GPU training\n",
    "strategy = tf.distribute.OneDeviceStrategy('GPU:0')  # Use the first GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339825, 300)\n",
      "(1335481, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m######################\n",
      "# RNN Model Training #\n",
      "######################\u001b[0m\n",
      "Epoch 1/10\n",
      "33387/33387 [==============================] - 3916s 117ms/step - loss: 0.4924 - accuracy: 0.8159 - val_loss: 2.3420 - val_accuracy: 0.3597\n",
      "Epoch 2/10\n",
      "33387/33387 [==============================] - 4122s 123ms/step - loss: 0.1417 - accuracy: 0.9553 - val_loss: 2.2152 - val_accuracy: 0.4851\n",
      "Epoch 3/10\n",
      "33387/33387 [==============================] - 3928s 118ms/step - loss: 0.5712 - accuracy: 0.7648 - val_loss: 2.7345 - val_accuracy: 7.5628e-04\n",
      "Epoch 4/10\n",
      "33387/33387 [==============================] - 3910s 117ms/step - loss: 1.1221 - accuracy: 0.4998 - val_loss: 2.5596 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "33387/33387 [==============================] - 3903s 117ms/step - loss: 0.5330 - accuracy: 0.8033 - val_loss: 2.0495 - val_accuracy: 0.2338\n",
      "Epoch 6/10\n",
      "33387/33387 [==============================] - 3891s 117ms/step - loss: 0.2145 - accuracy: 0.9293 - val_loss: 2.1012 - val_accuracy: 0.3566\n",
      "Epoch 7/10\n",
      "33387/33387 [==============================] - 3880s 116ms/step - loss: 0.1335 - accuracy: 0.9575 - val_loss: 2.2820 - val_accuracy: 0.4121\n",
      "Epoch 8/10\n",
      "33387/33387 [==============================] - 3888s 116ms/step - loss: 0.1034 - accuracy: 0.9679 - val_loss: 2.0511 - val_accuracy: 0.4817\n",
      "Epoch 9/10\n",
      "33387/33387 [==============================] - 3879s 116ms/step - loss: 0.0843 - accuracy: 0.9743 - val_loss: 1.7787 - val_accuracy: 0.5633\n",
      "Epoch 10/10\n",
      "33387/33387 [==============================] - 3827s 115ms/step - loss: 0.5690 - accuracy: 0.7920 - val_loss: 3.2577 - val_accuracy: 0.0164\n"
     ]
    }
   ],
   "source": [
    "# Reshape the input data to have an additional dimension\n",
    "X_train_resampled = np.reshape(X_train_resampled, (X_train_resampled.shape[0], X_train_resampled.shape[1], 1))\n",
    "X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "# RNN (LSTM) model\n",
    "print_decorative_log(\"RNN Model Training\", Fore.YELLOW)\n",
    "with strategy.scope():\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, input_shape=(X_train_resampled.shape[1],1)),\n",
    "        tf.keras.layers.Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    rnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    rnn_model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m########################\n",
      "# RNN Model Evaluation #\n",
      "########################\u001b[0m\n",
      "2655/2655 [==============================] - 104s 39ms/step\n",
      "RNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.01      0.39      0.02       512\n",
      "         1.0       0.02      0.58      0.04       540\n",
      "         2.0       0.01      0.02      0.02       506\n",
      "         3.0       0.99      0.60      0.75     83399\n",
      "\n",
      "    accuracy                           0.60     84957\n",
      "   macro avg       0.26      0.40      0.21     84957\n",
      "weighted avg       0.98      0.60      0.74     84957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the test data\n",
    "print_decorative_log(\"RNN Model Evaluation\", Fore.YELLOW)\n",
    "rnn_predictions = rnn_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class labels\n",
    "predicted_labels = np.argmax(rnn_predictions, axis=1)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rnn_report = classification_report(y_test, predicted_labels)\n",
    "print(\"RNN Classification Report:\")\n",
    "print(rnn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m######################\n",
      "# RNN Model Exported #\n",
      "######################\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MUSA\\anaconda3\\envs\\NeuroGuard\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model as an HDF5 file\n",
    "rnn_model.save(\"rnn_epilepsy_prediction_model.h5\")\n",
    "print_decorative_log(\"RNN Model Exported\", Fore.GREEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m######################\n",
      "# CNN Model Training #\n",
      "######################\u001b[0m\n",
      "Epoch 1/10\n",
      "33387/33387 [==============================] - 319s 9ms/step - loss: 0.0708 - accuracy: 0.9780 - val_loss: 1.2430 - val_accuracy: 0.7631\n",
      "Epoch 2/10\n",
      "33387/33387 [==============================] - 307s 9ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 1.1361 - val_accuracy: 0.7794\n",
      "Epoch 3/10\n",
      "33387/33387 [==============================] - 311s 9ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.8219 - val_accuracy: 0.8387\n",
      "Epoch 4/10\n",
      "33387/33387 [==============================] - 318s 10ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.6053 - val_accuracy: 0.8670\n",
      "Epoch 5/10\n",
      "33387/33387 [==============================] - 318s 10ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.6690 - val_accuracy: 0.8586\n",
      "Epoch 6/10\n",
      "33387/33387 [==============================] - 312s 9ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.2925 - val_accuracy: 0.9283\n",
      "Epoch 7/10\n",
      "33387/33387 [==============================] - 306s 9ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.5185 - val_accuracy: 0.8849\n",
      "Epoch 8/10\n",
      "33387/33387 [==============================] - 321s 10ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.6583 - val_accuracy: 0.8707\n",
      "Epoch 9/10\n",
      "33387/33387 [==============================] - 320s 10ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.4249 - val_accuracy: 0.9090\n",
      "Epoch 10/10\n",
      "33387/33387 [==============================] - 305s 9ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.2727 - val_accuracy: 0.9356\n"
     ]
    }
   ],
   "source": [
    "# Reshape the input data to have an additional dimension\n",
    "X_train_resampled = np.reshape(X_train_resampled, (X_train_resampled.shape[0], X_train_resampled.shape[1], 1))\n",
    "X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "# CNN model\n",
    "print_decorative_log(\"CNN Model Training\", Fore.YELLOW)\n",
    "with strategy.scope():\n",
    "    cnn_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_resampled.shape[1], 1)),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    cnn_model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m########################\n",
      "# CNN Model Evaluation #\n",
      "########################\u001b[0m\n",
      "2655/2655 [==============================] - 8s 3ms/step\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.84       512\n",
      "         1.0       0.86      0.92      0.89       540\n",
      "         2.0       0.78      0.85      0.81       506\n",
      "         3.0       1.00      1.00      1.00     83399\n",
      "\n",
      "    accuracy                           1.00     84957\n",
      "   macro avg       0.86      0.91      0.89     84957\n",
      "weighted avg       1.00      1.00      1.00     84957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "print_decorative_log(\"CNN Model Evaluation\", Fore.YELLOW)\n",
    "cnn_predictions = cnn_model.predict(X_test_scaled)\n",
    "# Get the predicted class labels\n",
    "predicted_labels = np.argmax(cnn_predictions, axis=1)\n",
    "\n",
    "cnn_report = classification_report(y_test, predicted_labels)\n",
    "print(\"CNN Classification Report:\")\n",
    "print(cnn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m######################\n",
      "# CNN Model Exported #\n",
      "######################\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Export the trained SVM model to a pickle file\n",
    "with open('cnn_epilepsy_prediction_model.pkl', 'wb') as file:\n",
    "    pickle.dump(cnn_model, file)\n",
    "print_decorative_log(\"CNN Model Exported\", Fore.GREEN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m######################\n",
      "# CNN Model Exported #\n",
      "######################\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MUSA\\anaconda3\\envs\\NeuroGuard\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model as an HDF5 file\n",
    "cnn_model.save(\"cnn_epilepsy_prediction_model.h5\")\n",
    "print_decorative_log(\"CNN Model Exported\", Fore.GREEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84957,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuroGuard-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
